{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot imports\n",
    "import matplotlib.pyplot as plt\n",
    "from lc_tda.plot import rcparams, format_axis_im\n",
    "\n",
    "# other imports\n",
    "import cv2\n",
    "import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from scipy.ndimage import zoom\n",
    "\n",
    "# format figures\n",
    "rcparams(1)\n",
    "\n",
    "# define color cycle\n",
    "COLOR = ['#515151', '#df5048', '#3370d8', '#5baa71',\n",
    "         '#a87bd8', '#c49b33', '#5bc8ca', '#76504f',\n",
    "         '#8e8c2b', '#ea6f2d', '#7099c8', '#80b537']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(\n",
    "    '/Volumes/Samsung_T5/Backup_20201218/data/lc_video/o3cl2/*/*.MP4')\n",
    "files += glob.glob('/Volumes/Samsung_T5/Backup_20201218/data/lc_video/o3cl2/*/*.mp4')\n",
    "files.sort()\n",
    "print(len(files))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load Endpoint Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_endpoint(file):\n",
    "    # locate the relative humidity from file name\n",
    "    conc = file.split('/')[-2].split('_')\n",
    "    conc_o3 = float(conc[0])\n",
    "    conc_cl2 = float(conc[1])\n",
    "\n",
    "    # capture the video\n",
    "    cap = cv2.VideoCapture(file)\n",
    "\n",
    "    # the length of the video\n",
    "    length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    # normally it reads the last frame\n",
    "    # but sometimes, the last few frames are blank\n",
    "    # so I use a while loop to locate the last frame\n",
    "    flag = True\n",
    "    j = 1\n",
    "    while flag:\n",
    "        try:\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, length - j)\n",
    "            res, frame = cap.read()\n",
    "            # convert bgr to rgb\n",
    "            img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            flag = False\n",
    "        except:\n",
    "            j += 1\n",
    "\n",
    "    nx, ny, nc = img.shape\n",
    "    max_length = int((length - j) / 30)\n",
    "\n",
    "    vid = np.zeros(shape=(150, nx, ny, nc))\n",
    "\n",
    "    for i in range(150):\n",
    "        if i < max_length:\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, i * 30)\n",
    "\n",
    "            res, frame = cap.read()\n",
    "\n",
    "            vid_ = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            vid[i, ...] = vid_\n",
    "        else:\n",
    "            vid[i, ...] = vid_\n",
    "\n",
    "    return vid, conc_o3, conc_cl2, img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_end_frame():\n",
    "    fig, ax = plt.subplots(nrows=11, ncols=5, figsize=(12, 16.5))\n",
    "    ax = ax.ravel()\n",
    "    for i in range(55):\n",
    "        if i < len(files):\n",
    "            img, conc_o3, conc_cl2 = extract_endpoint(files[i])\n",
    "            ax[i].imshow(img)\n",
    "            ax[i].set_title(f'{i}-{conc_o3:0.1f}-{conc_cl2:0.1f}', fontsize=12)\n",
    "        format_axis_im(ax[i])\n",
    "        ax[i].axis('off')\n",
    "    plt.savefig('endpoint.png', bbox_inches='tight', dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "plot_end_frame()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Locate Box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(vid, d=100):\n",
    "    \"\"\"\n",
    "    A function to crop and normalize images.\n",
    "    Args:\n",
    "        img: numpy array, image\n",
    "        d: int, side length\n",
    "\n",
    "    Returns:\n",
    "        img: numpy array, processed image\n",
    "    \"\"\"\n",
    "    dt, dx, dy, _ = vid.shape\n",
    "\n",
    "    hx = int(dx / 2)\n",
    "    hy = int(dy / 2)\n",
    "    hd = int(d / 2)\n",
    "\n",
    "    # select the center\n",
    "    vid = vid[:, hx - hd:hx + hd, hy - hd:hy + hd, :]\n",
    "\n",
    "    # normalize the images\n",
    "    vid = vid / 255.0\n",
    "\n",
    "    vid = zoom(vid, zoom=(1, 50/d, 50/d, 1))\n",
    "\n",
    "    return vid\n",
    "\n",
    "\n",
    "def crop(vid, dmin=130, dmax=150, normalize=True, img_final=None):\n",
    "    \"\"\"\n",
    "    A function to crop the boxes from the frame.\n",
    "    Args:\n",
    "        img: numpy array, image\n",
    "\n",
    "    Returns:\n",
    "        box: list, contains cropped box images\n",
    "    \"\"\"\n",
    "    # convert to grayscale\n",
    "    if normalize:\n",
    "        vid = vid / np.max(vid) * 255\n",
    "    vid = vid.astype(np.uint8)\n",
    "\n",
    "    if img_final is None:\n",
    "        img = vid[-1, ...]\n",
    "    else:\n",
    "        img = img_final\n",
    "\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    # define threshold\n",
    "    thresh = cv2.threshold(\n",
    "        gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "    # find contours\n",
    "    contours, hierarchy = cv2.findContours(\n",
    "        thresh, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    box = []\n",
    "    for c in contours:\n",
    "        # get the bounding rect\n",
    "        x, y, w, h = cv2.boundingRect(c)\n",
    "\n",
    "        # only if the box width and height in correct range\n",
    "        if (w > dmin) and (w < dmax) and (h > dmin) and (h < dmax):\n",
    "            box.append(vid[:, y:y + h, x:x + w, :])\n",
    "\n",
    "    return box\n",
    "\n",
    "\n",
    "def select_best(box, best_k=50, d=100):\n",
    "    \"\"\"\n",
    "    A function to select the best k images for each relative humidity\n",
    "    Args:\n",
    "        box: list, contains cropped box images\n",
    "\n",
    "    Returns:\n",
    "        box: list, contains the best k cropped box images\n",
    "    \"\"\"\n",
    "    # number of empty pixels\n",
    "    box_emp = [len(np.where(box[i][-1, ...].mean(axis=-1) <= 45)[0])\n",
    "               for i in range(len(box))]\n",
    "\n",
    "    # select the images with less empty pixels (bad images)\n",
    "    box_ind = np.argsort(box_emp)[:best_k]\n",
    "    box = [preprocess(box[i], d=d) for i in box_ind]\n",
    "    return box\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Crop Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_data(best_k=50, plot=False):\n",
    "    conc = np.array([files[i].split('/')[-2] for i in range(len(files))])\n",
    "\n",
    "    conc_unique = np.unique(conc)\n",
    "\n",
    "    x = []\n",
    "    y = []\n",
    "    for conc_unique_ in conc_unique:\n",
    "        idx = np.where(conc == conc_unique_)[0]\n",
    "\n",
    "        # extract endpoint frame\n",
    "        max_int = []\n",
    "        box = []\n",
    "        for i in idx:\n",
    "            vid, conc_o3, conc_cl2, _ = extract_endpoint(files[i])\n",
    "            # append box images for each frame\n",
    "            box_ = crop(vid)\n",
    "            box += box_\n",
    "        x += select_best(box, best_k)\n",
    "\n",
    "        conc_o3 = np.ones((best_k, 1)) * conc_o3\n",
    "        conc_cl2 = np.ones((best_k, 1)) * conc_cl2\n",
    "        conc_comb = np.concatenate((conc_o3, conc_cl2), axis=-1)\n",
    "\n",
    "        y.append(conc_comb)\n",
    "\n",
    "        if plot:\n",
    "            fig, ax = plt.subplots(nrows=5, ncols=10, figsize=(10, 5))\n",
    "            ax = ax.ravel()\n",
    "            for j in range(best_k):\n",
    "                ax[j].imshow(x[j, -1, ...])\n",
    "                ax[j].axis('off')\n",
    "            plt.savefig(f'endpoint_{conc_unique_}.png',\n",
    "                        dpi=300, bbox_inches='tight')\n",
    "            plt.close()\n",
    "    x = np.array(x)\n",
    "\n",
    "    y = np.concatenate(y, axis=0)\n",
    "\n",
    "    with open('../data/o3cl2/video.pickle', 'wb') as handle:\n",
    "        pickle.dump(x, handle)\n",
    "        pickle.dump(y, handle)\n",
    "    print(f'x: {x.shape}, y: {y.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('py38tf230')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d2d15e1cb7beee1bb00669c88f6cbcba6c97eb1909d2bd867934bd2967989dee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
